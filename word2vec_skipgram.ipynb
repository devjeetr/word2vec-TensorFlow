{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import random\n",
    "import math\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text8_filepath = \"text8.zip\"\n",
    "\n",
    "def loadFile(filename):\n",
    "    with zipfile.ZipFile(filename) as _zipfile:\n",
    "        with _zipfile.open(_zipfile.namelist()[0]) as data_file:\n",
    "            data = tf.compat.as_str(data_file.read()).split()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [[\"UNK\", -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    \n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "        \n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    \n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(n, data, batch_size=10, num_skips=10, skip_window=5):\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    \n",
    "    span = 2 * skip_window + 1\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    \n",
    "    if n + span > len(data):\n",
    "        n = 0\n",
    "    \n",
    "    buffer.extend(data[n: n + span])\n",
    "    n += span\n",
    "    for i in range(batch_size // num_skips):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "        \n",
    "        if n == len(data):\n",
    "            buffer[:] = data[:span]\n",
    "            n = span\n",
    "        else:\n",
    "            buffer.append(data[n])\n",
    "            n += 1\n",
    "        \n",
    "    n =  (n + len(data) - span) % len(data)\n",
    "\n",
    "    return batch, labels, n\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# batch, labels, n = generate_batch(n, data, batch_size=8, num_skips=2, skip_window=1)\n",
    "# # print(labels[1: 10])\n",
    "# for i in range(8):\n",
    "#         print(batch[i], reverse_dictionary[batch[i]],\n",
    "#             '->', labels[i, 0], reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f4bc7d39ce78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalid_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Graph'"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128\n",
    "skip_window = 1\n",
    "num_skips = 2\n",
    "num_sampled = 64\n",
    "vocabulary_size = 50000\n",
    "\n",
    "valid_size = 16\n",
    "valid_window = 100\n",
    "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    training_data = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    training_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    validation_set = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], \n",
    "                                                -1.0, 1.0))\n",
    "    \n",
    "    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], \n",
    "                                                       stddev=1.0/math.sqrt(embedding_size)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "    \n",
    "    # Model\n",
    "    embed = tf.nn.embedding_lookup(embeddings, training_data)\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed,\n",
    "                                  labels=training_labels, num_sampled=num_sampled, num_classes=vocabulary_size)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    # compute similarity between\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, validation_set)\n",
    "    \n",
    "    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-75a0237ca0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext8_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maverage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgraph_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8d025d480ade>\u001b[0m in \u001b[0;36mloadFile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_zipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_zipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "raw_text = loadFile(text8_filepath)\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(raw_text, vocabulary_size)\n",
    "average_loss = 0\n",
    "graph_data = []\n",
    "graph_data_polling_interval = 500\n",
    "num_points = 400\n",
    "\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    n = 0\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        batch_data, batch_labels, n = generate_batch(n, data, batch_size=batch_size, \n",
    "                                                num_skips=num_skips, skip_window=skip_window)\n",
    "        \n",
    "        feed_dict = {training_data: batch_data, \n",
    "                     training_labels: batch_labels}\n",
    "        \n",
    "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        \n",
    "        average_loss += l\n",
    "        if step % graph_data_polling_interval == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / graph_data_polling_interval\n",
    "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "#             print('Average loss at step %d: %f' % (step, average_loss))\n",
    "            current_embeddings = get_flattened_embeddings(normalized_embeddings.eval()[:num_points + 1])\n",
    "            graph_data.append(flattened_embedding_to_graph_data(current_embeddings, words))\n",
    "            average_loss = 0\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            print(\"Step {}\".format(step))\n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1b79dfe7cc85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'exact'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtwo_d_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "num_points = 400\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])\n",
    "\n",
    "\n",
    "def plot(embeddings, labels):\n",
    "    assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    pylab.figure(figsize=(15,15))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i,:]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                       ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "\n",
    "words = [reverse_dictionary[i] for i in range(1, num_points+1)]\n",
    "plot(two_d_embeddings, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_embeddings(embeddings):\n",
    "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "    embeddings = tsne.fit_transform(embeddings[1:, :])\n",
    "    return embeddings\n",
    "\n",
    "def flattened_embedding_to_graph_data(embeddings, labels):\n",
    "    return [[a, b, c] for (a, b), c in zip(embeddings.tolist(), words)]\n",
    "\n",
    "flattened_embeddings = get_flattened_embeddings(final_embeddings[:num_points, :])\n",
    "_data = flattened_embedding_to_graph_data(flattened_embeddings, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-41.31324768066406, 25.045658111572266, 'the'],\n",
       " [18.37194061279297, 28.956485748291016, 'of'],\n",
       " [11.772801399230957, 25.642641067504883, 'and'],\n",
       " [42.3211669921875, -20.980093002319336, 'one'],\n",
       " [24.41452980041504, 48.44853591918945, 'in'],\n",
       " [-38.73276901245117, 26.362993240356445, 'a'],\n",
       " [-40.42744827270508, 54.632171630859375, 'to'],\n",
       " [40.240360260009766, -29.392635345458984, 'zero'],\n",
       " [47.403594970703125, -26.09493064880371, 'nine'],\n",
       " [40.764522552490234, -23.179250717163086, 'two'],\n",
       " [35.698543548583984, 22.321081161499023, 'is'],\n",
       " [27.963716506958008, 33.358604431152344, 'as'],\n",
       " [46.277313232421875, -28.03636932373047, 'eight'],\n",
       " [11.868157386779785, 42.699676513671875, 'for'],\n",
       " [-49.99739074707031, 17.042314529418945, 's'],\n",
       " [42.330833435058594, -27.11469268798828, 'five'],\n",
       " [43.099945068359375, -24.7246150970459, 'three'],\n",
       " [37.11980438232422, 22.270479202270508, 'was'],\n",
       " [24.714427947998047, 31.831531524658203, 'by'],\n",
       " [-11.484792709350586, 51.977447509765625, 'that'],\n",
       " [40.441898345947266, -26.166038513183594, 'four'],\n",
       " [44.06085205078125, -29.034263610839844, 'six'],\n",
       " [45.01310729980469, -26.5761661529541, 'seven'],\n",
       " [20.688791275024414, 52.979740142822266, 'with'],\n",
       " [26.421539306640625, 46.59748458862305, 'on'],\n",
       " [22.720504760742188, 18.89109992980957, 'are'],\n",
       " [-19.357177734375, 48.511962890625, 'it'],\n",
       " [24.233901977539062, 40.2373161315918, 'from'],\n",
       " [10.961069107055664, 24.40508460998535, 'or'],\n",
       " [-45.068973541259766, 20.141244888305664, 'his'],\n",
       " [-41.0418815612793, 30.104665756225586, 'an'],\n",
       " [35.616085052490234, 27.748455047607422, 'be'],\n",
       " [-15.791047096252441, 51.18084716796875, 'this'],\n",
       " [-12.93695068359375, 51.46470642089844, 'which'],\n",
       " [25.261932373046875, 51.26621627807617, 'at'],\n",
       " [-19.327667236328125, 45.68801498413086, 'he'],\n",
       " [-8.416853904724121, 39.83243942260742, 'also'],\n",
       " [-14.776948928833008, 39.61154556274414, 'not'],\n",
       " [27.21705436706543, 21.96309471130371, 'have'],\n",
       " [23.689489364624023, 18.02810287475586, 'were'],\n",
       " [29.89922523498535, 20.922395706176758, 'has'],\n",
       " [6.377899646759033, 28.120378494262695, 'but'],\n",
       " [24.952091217041016, 0.5635008215904236, 'other'],\n",
       " [-44.69917678833008, 22.39118194580078, 'their'],\n",
       " [-45.9311637878418, 23.381149291992188, 'its'],\n",
       " [5.506338119506836, 6.246669769287109, 'first'],\n",
       " [-23.6593017578125, 41.20376205444336, 'they'],\n",
       " [24.924209594726562, 8.1300687789917, 'some'],\n",
       " [29.056655883789062, 22.264205932617188, 'had'],\n",
       " [28.608123779296875, 6.864191055297852, 'all'],\n",
       " [5.075594902038574, 51.203025817871094, 'more'],\n",
       " [7.396575927734375, 49.779685974121094, 'most'],\n",
       " [-39.201820373535156, 49.63644027709961, 'can'],\n",
       " [37.97923278808594, 28.1717529296875, 'been'],\n",
       " [-8.988256454467773, 14.77503490447998, 'such'],\n",
       " [23.63300323486328, 7.053598880767822, 'many'],\n",
       " [-15.461454391479492, 44.51261901855469, 'who'],\n",
       " [22.161405563354492, -4.179712295532227, 'new'],\n",
       " [-13.40355396270752, 18.66086769104004, 'used'],\n",
       " [-20.92499542236328, 41.046077728271484, 'there'],\n",
       " [16.11915397644043, 40.57319641113281, 'after'],\n",
       " [10.498101234436035, 36.669700622558594, 'when'],\n",
       " [26.719173431396484, 42.02297592163086, 'into'],\n",
       " [9.37023639678955, -46.99953842163086, 'american'],\n",
       " [-9.886816024780273, -6.532392978668213, 'time'],\n",
       " [22.40148162841797, 9.917150497436523, 'these'],\n",
       " [0.40421262383461, 11.332478523254395, 'only'],\n",
       " [0.6759656071662903, -57.83576965332031, 'see'],\n",
       " [-37.109615325927734, 49.66887664794922, 'may'],\n",
       " [-5.613672733306885, 6.298535346984863, 'than'],\n",
       " [3.5763161182403564, -34.002052307128906, 'world'],\n",
       " [-27.877243041992188, 43.51382064819336, 'i'],\n",
       " [34.34897994995117, -55.56272888183594, 'b'],\n",
       " [-42.24745559692383, 48.86601257324219, 'would'],\n",
       " [35.445613861083984, -54.95714569091797, 'd'],\n",
       " [35.80027389526367, 11.002193450927734, 'no'],\n",
       " [5.1483564376831055, 29.24222183227539, 'however'],\n",
       " [20.405654907226562, 49.82456588745117, 'between'],\n",
       " [30.461185455322266, 45.690372467041016, 'about'],\n",
       " [32.76712417602539, 46.94549560546875, 'over'],\n",
       " [-8.531170845031738, -14.951604843139648, 'years'],\n",
       " [-6.262860298156738, -34.713844299316406, 'states'],\n",
       " [-35.772830963134766, -21.309240341186523, 'people'],\n",
       " [-14.577155113220215, -24.080644607543945, 'war'],\n",
       " [19.395090103149414, 40.467872619628906, 'during'],\n",
       " [14.11440658569336, 10.664848327636719, 'united'],\n",
       " [-12.067289352416992, 16.330076217651367, 'known'],\n",
       " [10.324188232421875, 38.44054412841797, 'if'],\n",
       " [-19.079326629638672, 13.405975341796875, 'called'],\n",
       " [-3.0546391010284424, 18.671918869018555, 'use'],\n",
       " [48.09233093261719, -20.534473419189453, 'th'],\n",
       " [-23.505605697631836, -40.0162239074707, 'system'],\n",
       " [-7.93936014175415, 43.989906311035156, 'often'],\n",
       " [-9.779203414916992, -28.540882110595703, 'state'],\n",
       " [1.4281697273254395, 43.414642333984375, 'so'],\n",
       " [-16.643310546875, -13.348714828491211, 'history'],\n",
       " [-41.3942756652832, 50.86527633666992, 'will'],\n",
       " [42.144142150878906, 45.28938293457031, 'up'],\n",
       " [7.103514671325684, 33.715187072753906, 'while'],\n",
       " [7.282558917999268, 36.896827697753906, 'where'],\n",
       " [-8.719706535339355, -26.002628326416016, 'city'],\n",
       " [31.232343673706055, 27.442020416259766, 'being'],\n",
       " [15.475265502929688, -49.243839263916016, 'english'],\n",
       " [-2.567959785461426, 38.179588317871094, 'then'],\n",
       " [34.10642623901367, 9.020401954650879, 'any'],\n",
       " [27.6639461517334, 4.189598560333252, 'both'],\n",
       " [21.813310623168945, 44.188350677490234, 'under'],\n",
       " [43.25505447387695, 43.618595123291016, 'out'],\n",
       " [-22.79591178894043, 19.737205505371094, 'made'],\n",
       " [-7.593942165374756, 13.040170669555664, 'well'],\n",
       " [-44.5169792175293, 18.746034622192383, 'her'],\n",
       " [37.009578704833984, -45.71925735473633, 'e'],\n",
       " [-15.953238487243652, 3.384777307510376, 'number'],\n",
       " [-10.65063762664795, -30.207754135131836, 'government'],\n",
       " [-39.815513610839844, 9.426688194274902, 'them'],\n",
       " [44.29105758666992, -48.60946273803711, 'm'],\n",
       " [-2.1258490085601807, 35.67887496948242, 'later'],\n",
       " [19.30995750427246, 34.93920135498047, 'since'],\n",
       " [-41.10964584350586, 9.105948448181152, 'him'],\n",
       " [-10.780080795288086, 5.199234962463379, 'part'],\n",
       " [3.9439902305603027, 15.115478515625, 'name'],\n",
       " [35.88837814331055, -47.62858200073242, 'c'],\n",
       " [-5.100305080413818, -11.238770484924316, 'century'],\n",
       " [24.842161178588867, 42.68708801269531, 'through'],\n",
       " [12.778331756591797, 35.361175537109375, 'because'],\n",
       " [34.3512077331543, -39.84150695800781, 'x'],\n",
       " [4.606415748596191, -20.7036075592041, 'university'],\n",
       " [-1.6876872777938843, -1.9493474960327148, 'early'],\n",
       " [-24.96514129638672, -23.709484100341797, 'life'],\n",
       " [10.753471374511719, -45.748783111572266, 'british'],\n",
       " [-7.6010236740112305, -10.766074180603027, 'year'],\n",
       " [16.171648025512695, 26.288711547851562, 'like'],\n",
       " [9.649867057800293, 10.454846382141113, 'same'],\n",
       " [18.20439338684082, 26.31793975830078, 'including'],\n",
       " [39.217437744140625, 22.585704803466797, 'became'],\n",
       " [0.5778209567070007, 17.25128936767578, 'example'],\n",
       " [-7.046055316925049, -8.215213775634766, 'day'],\n",
       " [33.72230529785156, 6.8910298347473145, 'each'],\n",
       " [-0.6676905155181885, 25.404184341430664, 'even'],\n",
       " [-28.645517349243164, -16.84564208984375, 'work'],\n",
       " [-47.23571014404297, -26.094867706298828, 'language'],\n",
       " [8.252164840698242, 32.1735725402832, 'although'],\n",
       " [22.684642791748047, 5.543853282928467, 'several'],\n",
       " [-15.221776008605957, -8.808028221130371, 'form'],\n",
       " [47.67264938354492, -44.78748321533203, 'john'],\n",
       " [4.878961563110352, -31.965517044067383, 'u'],\n",
       " [-3.6844780445098877, -47.569637298583984, 'national'],\n",
       " [2.1802234649658203, 49.58635711669922, 'very'],\n",
       " [-8.115560531616211, 6.342065334320068, 'much'],\n",
       " [39.489566802978516, -41.02069854736328, 'g'],\n",
       " [14.447615623474121, -46.22230529785156, 'french'],\n",
       " [15.559155464172363, 39.261722564697266, 'before'],\n",
       " [11.255874633789062, -9.502263069152832, 'general'],\n",
       " [-9.030733108520508, 54.883872985839844, 'what'],\n",
       " [-31.510257720947266, 41.6885986328125, 't'],\n",
       " [18.69618034362793, 45.4129524230957, 'against'],\n",
       " [35.53252029418945, -42.4979362487793, 'n'],\n",
       " [25.700489044189453, -12.824417114257812, 'high'],\n",
       " [1.5265944004058838, -59.86082458496094, 'links'],\n",
       " [-40.44044494628906, 47.70661544799805, 'could'],\n",
       " [-26.28231430053711, 11.626567840576172, 'based'],\n",
       " [23.217361450195312, 13.301302909851074, 'those'],\n",
       " [-11.529959678649902, 38.951107025146484, 'now'],\n",
       " [3.757962465286255, 4.522669315338135, 'second'],\n",
       " [28.378108978271484, -49.659523010253906, 'de'],\n",
       " [-42.28322219848633, -9.109888076782227, 'music'],\n",
       " [-38.667724609375, 28.441898345947266, 'another'],\n",
       " [28.28636360168457, -8.14098072052002, 'large'],\n",
       " [-20.616792678833008, 45.97587203979492, 'she'],\n",
       " [42.5299072265625, -42.155418395996094, 'f'],\n",
       " [-1.5953733921051025, -55.22096633911133, 'external'],\n",
       " [13.903902053833008, -47.44745635986328, 'german'],\n",
       " [21.806333541870117, -1.695522427558899, 'different'],\n",
       " [17.904916763305664, -8.295416831970215, 'modern'],\n",
       " [30.40758514404297, -6.714969635009766, 'great'],\n",
       " [-42.87435531616211, 40.89765167236328, 'do'],\n",
       " [14.754589080810547, -5.6647467613220215, 'common'],\n",
       " [-21.093496322631836, 2.546809196472168, 'set'],\n",
       " [-15.407793045043945, -12.723413467407227, 'list'],\n",
       " [19.161527633666992, -24.83488655090332, 'south'],\n",
       " [-21.0946102142334, -11.537483215332031, 'series'],\n",
       " [14.31643295288086, 1.6296095848083496, 'major'],\n",
       " [-36.994651794433594, -5.418287754058838, 'game'],\n",
       " [-21.23114013671875, -43.5494270324707, 'power'],\n",
       " [45.06120300292969, 3.3849363327026367, 'long'],\n",
       " [2.491286277770996, -31.093372344970703, 'country'],\n",
       " [-31.10236167907715, -30.836055755615234, 'king'],\n",
       " [-23.14133644104004, -5.751530170440674, 'law'],\n",
       " [-45.28196716308594, -16.383636474609375, 'group'],\n",
       " [-42.61519241333008, -7.063683032989502, 'film'],\n",
       " [-11.029504776000977, 41.23813247680664, 'still'],\n",
       " [18.25041961669922, 36.09339904785156, 'until'],\n",
       " [18.16590690612793, -23.843303680419922, 'north'],\n",
       " [4.833595275878906, -46.25255584716797, 'international'],\n",
       " [4.88432502746582, 18.189044952392578, 'term'],\n",
       " [-25.83612632751465, 41.47702407836914, 'we'],\n",
       " [4.349922180175781, -4.281152725219727, 'end'],\n",
       " [-23.09139060974121, -16.60053825378418, 'book'],\n",
       " [-12.386502265930176, 21.913724899291992, 'found'],\n",
       " [-7.1057024002075195, -56.221046447753906, 'own'],\n",
       " [-1.7506769895553589, -40.87959671020508, 'political'],\n",
       " [-12.189925193786621, -34.14299011230469, 'party'],\n",
       " [-17.50221824645996, -4.004373550415039, 'order'],\n",
       " [-9.267932891845703, 45.0658073425293, 'usually'],\n",
       " [-2.334127426147461, -23.796581268310547, 'president'],\n",
       " [-18.55698585510254, -25.992591857910156, 'church'],\n",
       " [-26.883562088012695, 40.04060363769531, 'you'],\n",
       " [-26.852521896362305, -24.293941497802734, 'death'],\n",
       " [-21.073087692260742, -32.40010070800781, 'theory'],\n",
       " [-38.90199661254883, -38.208457946777344, 'area'],\n",
       " [29.399015426635742, 48.3883056640625, 'around'],\n",
       " [19.803022384643555, 24.372411727905273, 'include'],\n",
       " [-30.59441375732422, -28.89883804321289, 'god'],\n",
       " [-28.409000396728516, 45.529537200927734, 'ii'],\n",
       " [-9.675954818725586, -4.393757343292236, 'way'],\n",
       " [-44.00212478637695, 43.61326217651367, 'did'],\n",
       " [-7.235179424285889, -42.10687255859375, 'military'],\n",
       " [-30.40459632873535, 2.3931801319122314, 'population'],\n",
       " [24.403881072998047, 30.000171661376953, 'using'],\n",
       " [9.871140480041504, 32.654903411865234, 'though'],\n",
       " [27.036636352539062, -8.173168182373047, 'small'],\n",
       " [11.663257598876953, 11.312504768371582, 'following'],\n",
       " [22.560306549072266, 47.73775100708008, 'within'],\n",
       " [12.453340530395508, 54.992862701416016, 'non'],\n",
       " [33.45156478881836, -13.407732963562012, 'human'],\n",
       " [2.046128273010254, -8.865827560424805, 'left'],\n",
       " [12.854204177856445, 4.123874664306641, 'main'],\n",
       " [17.635339736938477, 50.32774353027344, 'among'],\n",
       " [-22.241100311279297, -1.218592643737793, 'point'],\n",
       " [38.78758239746094, -43.40134811401367, 'r'],\n",
       " [-23.150365829467773, 29.70854949951172, 'due'],\n",
       " [41.75790786743164, -47.120277404785156, 'p'],\n",
       " [-16.03436851501465, 17.323673248291016, 'considered'],\n",
       " [11.512191772460938, -16.914339065551758, 'public'],\n",
       " [15.684511184692383, -6.882633209228516, 'popular'],\n",
       " [0.1806952804327011, -15.856362342834473, 'computer'],\n",
       " [21.49099349975586, -22.620336532592773, 'west'],\n",
       " [-33.85203170776367, -27.646900177001953, 'family'],\n",
       " [22.904428482055664, -22.62198257446289, 'east'],\n",
       " [-18.09844398498535, -51.0546875, 'information'],\n",
       " [11.228273391723633, -2.662386655807495, 'important'],\n",
       " [8.870190620422363, -41.489036560058594, 'european'],\n",
       " [-36.673526763916016, -18.50290298461914, 'man'],\n",
       " [-6.309123992919922, 44.57417297363281, 'sometimes'],\n",
       " [2.6765942573547363, -7.811594009399414, 'right'],\n",
       " [-1.9438952207565308, 32.11287307739258, 'old'],\n",
       " [5.6851091384887695, -17.608783721923828, 'free'],\n",
       " [3.8263888359069824, 17.2034969329834, 'word'],\n",
       " [15.526749610900879, 43.62323760986328, 'without'],\n",
       " [6.6753764152526855, 7.816359996795654, 'last'],\n",
       " [-41.125396728515625, 4.119790554046631, 'us'],\n",
       " [-2.78999924659729, -21.75119972229004, 'members'],\n",
       " [-18.63776397705078, 21.15113639831543, 'given'],\n",
       " [-6.490414142608643, -16.179357528686523, 'times'],\n",
       " [18.019468307495117, -44.48147201538086, 'roman'],\n",
       " [-26.966604232788086, 20.03243637084961, 'make'],\n",
       " [39.479312896728516, -45.79601287841797, 'h'],\n",
       " [-13.98180103302002, -18.21442413330078, 'age'],\n",
       " [-13.233530044555664, -2.887312889099121, 'place'],\n",
       " [35.78216552734375, -50.31708908081055, 'l'],\n",
       " [-1.905173897743225, 40.04230499267578, 'thus'],\n",
       " [-27.62932586669922, -11.368924140930176, 'science'],\n",
       " [-21.808998107910156, -3.44564151763916, 'case'],\n",
       " [39.57183074951172, 27.651840209960938, 'become'],\n",
       " [-24.75885009765625, -40.27492904663086, 'systems'],\n",
       " [-9.823751449584961, -33.30820083618164, 'union'],\n",
       " [7.693149566650391, -10.918159484863281, 'born'],\n",
       " [20.096616744995117, -33.43037414550781, 'york'],\n",
       " [-29.1050968170166, -4.07956075668335, 'line'],\n",
       " [-42.78390884399414, -26.35687828063965, 'countries'],\n",
       " [-42.49966049194336, 43.75507354736328, 'does'],\n",
       " [-51.97114562988281, 15.286005020141602, 'isbn'],\n",
       " [50.33306884765625, -20.79051399230957, 'st'],\n",
       " [-18.94162368774414, -45.243648529052734, 'control'],\n",
       " [24.679445266723633, 2.737893581390381, 'various'],\n",
       " [-36.23773956298828, 11.690169334411621, 'others'],\n",
       " [-18.917909622192383, -19.22595977783203, 'house'],\n",
       " [-27.948715209960938, 11.832176208496094, 'article'],\n",
       " [-40.55610656738281, -39.267433166503906, 'island'],\n",
       " [-37.975669860839844, 47.05846405029297, 'should'],\n",
       " [-22.15662956237793, 25.560897827148438, 'led'],\n",
       " [41.841651916503906, 41.124576568603516, 'back'],\n",
       " [-11.663579940795898, -8.836420059204102, 'period'],\n",
       " [-34.873531341552734, -11.235032081604004, 'player'],\n",
       " [12.449674606323242, -30.484159469604492, 'europe'],\n",
       " [-45.97056198120117, -26.126888275146484, 'languages'],\n",
       " [22.168367385864258, -25.58993148803711, 'central'],\n",
       " [-28.880523681640625, -49.52370834350586, 'water'],\n",
       " [19.634782791137695, 4.2107253074646, 'few'],\n",
       " [18.873868942260742, -18.988059997558594, 'western'],\n",
       " [-8.783604621887207, -57.18756866455078, 'home'],\n",
       " [-26.8765869140625, 27.354246139526367, 'began'],\n",
       " [-11.02431583404541, 44.017234802246094, 'generally'],\n",
       " [3.8266756534576416, 51.56267547607422, 'less'],\n",
       " [42.28728485107422, -44.64618682861328, 'k'],\n",
       " [18.248315811157227, -2.381166458129883, 'similar'],\n",
       " [-16.069637298583984, 21.645536422729492, 'written'],\n",
       " [9.622506141662598, 6.0964035987854, 'original'],\n",
       " [2.2648980617523193, 9.048773765563965, 'best'],\n",
       " [-38.40530014038086, 51.96574401855469, 'must'],\n",
       " [-24.494186401367188, 29.664052963256836, 'according'],\n",
       " [7.258790969848633, -23.3610897064209, 'school'],\n",
       " [16.097013473510742, -32.91928482055664, 'france'],\n",
       " [-27.35960578918457, -50.34915542602539, 'air'],\n",
       " [0.5723684430122375, 2.8552463054656982, 'single'],\n",
       " [-11.420389175415039, -45.442138671875, 'force'],\n",
       " [39.32710647583008, -49.216697692871094, 'v'],\n",
       " [-29.43325424194336, 4.002476215362549, 'land'],\n",
       " [-46.194114685058594, -17.364473342895508, 'groups'],\n",
       " [40.00727462768555, 41.99586868286133, 'down'],\n",
       " [-7.955748558044434, 55.9423828125, 'how'],\n",
       " [-28.278461456298828, -18.138437271118164, 'works'],\n",
       " [2.8882837295532227, -45.168312072753906, 'development'],\n",
       " [-3.2776496410369873, -54.37277603149414, 'official'],\n",
       " [-12.231536865234375, -49.22421646118164, 'support'],\n",
       " [17.808218002319336, -33.10124969482422, 'england'],\n",
       " [45.246559143066406, -44.91964340209961, 'j'],\n",
       " [4.213860511779785, 54.33852767944336, 'rather'],\n",
       " [-19.203947067260742, -51.84105682373047, 'data'],\n",
       " [31.072853088378906, -38.41928482055664, 'space'],\n",
       " [17.945846557617188, -46.35840606689453, 'greek'],\n",
       " [35.27951431274414, -24.8618106842041, 'km'],\n",
       " [-19.59161376953125, 12.140359878540039, 'named'],\n",
       " [14.104727745056152, -32.241310119628906, 'germany'],\n",
       " [-6.739592552185059, 10.660955429077148, 'just'],\n",
       " [-37.467647552490234, -4.243478298187256, 'games'],\n",
       " [-19.05242919921875, 31.005456924438477, 'said'],\n",
       " [-18.915224075317383, -10.890289306640625, 'version'],\n",
       " [-2.760296583175659, -2.5686283111572266, 'late'],\n",
       " [-28.243562698364258, 6.3949055671691895, 'earth'],\n",
       " [-31.40767478942871, -6.1089253425598145, 'company'],\n",
       " [35.49554443359375, 6.4950337409973145, 'every'],\n",
       " [0.49909237027168274, -41.55156326293945, 'economic'],\n",
       " [45.035213470458984, 2.092832088470459, 'short'],\n",
       " [-14.694117546081543, 23.25887107849121, 'published'],\n",
       " [41.06675338745117, -6.832308769226074, 'black'],\n",
       " [-10.125298500061035, -41.85463333129883, 'army'],\n",
       " [40.21946334838867, 44.16648483276367, 'off'],\n",
       " [-7.633738040924072, -23.394611358642578, 'london'],\n",
       " [37.58745574951172, -30.464338302612305, 'million'],\n",
       " [-23.177457809448242, -26.001541137695312, 'body'],\n",
       " [-17.954471588134766, -31.606101989746094, 'field'],\n",
       " [18.022415161132812, -12.215555191040039, 'christian'],\n",
       " [31.026918411254883, 11.561169624328613, 'either'],\n",
       " [-0.6689862608909607, -39.92033386230469, 'social'],\n",
       " [-4.173158168792725, -29.84970474243164, 'empire'],\n",
       " [42.42020034790039, -51.74553680419922, 'o'],\n",
       " [-20.572311401367188, 22.67688751220703, 'developed'],\n",
       " [14.884176254272461, 16.269906997680664, 'standard'],\n",
       " [-26.976608276367188, -30.694852828979492, 'court'],\n",
       " [-8.951926231384277, -47.77357482910156, 'service'],\n",
       " [-5.084190368652344, -33.91476821899414, 'kingdom'],\n",
       " [38.742469787597656, 47.766143798828125, 'along'],\n",
       " [5.312124252319336, -22.128705978393555, 'college'],\n",
       " [-12.974342346191406, -30.11224365234375, 'republic'],\n",
       " [25.406211853027344, -20.246417999267578, 'sea'],\n",
       " [11.485823631286621, -28.951745986938477, 'america'],\n",
       " [-11.855744361877441, 35.42646026611328, 'today'],\n",
       " [-14.575793266296387, 3.9172415733337402, 'result'],\n",
       " [-10.52249813079834, 21.476154327392578, 'held'],\n",
       " [-34.29133987426758, -10.105939865112305, 'team'],\n",
       " [-30.90782928466797, -48.355918884277344, 'light'],\n",
       " [-8.728350639343262, -1.249475121498108, 'means'],\n",
       " [-6.5803303718566895, 38.60258102416992, 'never'],\n",
       " [0.912631630897522, 26.11524772644043, 'especially'],\n",
       " [2.9659230709075928, 3.2622063159942627, 'third'],\n",
       " [33.083526611328125, 42.36236572265625, 'further'],\n",
       " [-23.390785217285156, -29.595609664916992, 'character'],\n",
       " [-11.15600872039795, -43.5052604675293, 'forces'],\n",
       " [-29.575828552246094, 21.563148498535156, 'take'],\n",
       " [-36.845611572265625, -22.326072692871094, 'men'],\n",
       " [-26.570234298706055, -10.07516098022461, 'society'],\n",
       " [-44.51625442504883, -5.42620849609375, 'show'],\n",
       " [8.572555541992188, -3.5641181468963623, 'open'],\n",
       " [-13.088973999023438, 14.227544784545898, 'possible'],\n",
       " [-15.791308403015137, -2.4192090034484863, 'fact'],\n",
       " [-18.068912506103516, -37.56747817993164, 'battle'],\n",
       " [-30.034683227539062, 22.928476333618164, 'took'],\n",
       " [-1.658342719078064, -27.222593307495117, 'former'],\n",
       " [-24.3635196685791, -17.287540435791016, 'books'],\n",
       " [11.086104393005371, -41.9971923828125, 'soviet'],\n",
       " [-31.919601440429688, -37.980499267578125, 'river'],\n",
       " [-32.05487060546875, -22.42924690246582, 'children'],\n",
       " [29.836790084838867, 26.54766273498535, 'having'],\n",
       " [12.629992485046387, -14.82133674621582, 'good'],\n",
       " [-1.2642346620559692, -48.9514045715332, 'local'],\n",
       " [7.926226615905762, 3.9822943210601807, 'current'],\n",
       " [-29.716144561767578, -24.517101287841797, 'son'],\n",
       " [-20.72522735595703, -39.03156280517578, 'process'],\n",
       " [31.7778377532959, -11.896003723144531, 'natural'],\n",
       " [-8.740710258483887, 23.708293914794922, 'present'],\n",
       " [-42.928504943847656, 10.816628456115723, 'himself'],\n",
       " [-41.99094009399414, -40.066490173339844, 'islands'],\n",
       " [27.846296310424805, -14.64926815032959, 'total'],\n",
       " [28.083236694335938, 51.74948501586914, 'near'],\n",
       " [39.861881256103516, -7.244449615478516, 'white'],\n",
       " [-9.769966125488281, -15.389169692993164, 'days'],\n",
       " [-35.74559020996094, -16.89423942565918, 'person'],\n",
       " [-20.125009536743164, 51.13848876953125, 'itself']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_embeddings = get_flattened_embeddings(final_embeddings[:num_points, :])\n",
    "_data = flattened_embedding_to_graph_data(flattened_embeddings, words)\n",
    "_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_flattened_embeddings() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-26b9ba3f20cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgraph_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_flattened_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgraph_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_flattened_embeddings() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "def flattened_embedding_to_graph_data(embeddings, labels):\n",
    "    return [[a, b, c] for (a, b), c in zip(embeddings.tolist(), words)]\n",
    "\n",
    "graph_data = get_flattened_embeddings(final_embeddings[:num_points, :], words)\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
